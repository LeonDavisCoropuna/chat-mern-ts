# Laboratorio: Pruebas de Autoscaling usando IaC con Pulumi
By Leon Davis
- Github: https://github.com/LeonDavisCoropuna/chat-mern-ts.git 
- App disponible en: http://34.123.66.173
## Objetivo
Configurar un escenario de **autoscaling** en Google Kubernetes Engine (GKE) usando **Pulumi** como herramienta OPEN SOURCE de Infrastructure as Code (IaC).

## Configuraci√≥n Inicial

### Prerrequisitos
```bash
# Autenticaci√≥n en GCP
mkdir -p infra && cd infra
gcloud auth login
gcloud config set project chat-pulumi
gcloud auth application-default login

# Instalaci√≥n de Pulumi y dependencias
pulumi new typescript
npm install --save @pulumi/pulumi @pulumi/gcp @pulumi/kubernetes

# Configuraci√≥n del proyecto
pulumi config set gcp:project chat-pulimi
pulumi config set gcp:zone us-central1-c
```

### Archivos de Configuraci√≥n Generados

#### `Pulumi.yaml`
```yaml
name: chat-pulumi
description: Chat pulumi with autoscaling
runtime:
  name: nodejs
  options:
    packagemanager: npm
config:
  pulumi:tags:
    value:
      pulumi:template: typescript
```

#### `Pulumi.dev.yaml`
```yaml
config:
  gcp:project: chat-pulimi
  gcp:zone: us-central1-c
```

#### `kubeconfig.yaml` (generado autom√°ticamente)
Configuraci√≥n de acceso al cluster Kubernetes con autenticaci√≥n GCP.


## Arquitectura Kubernetes MERN Implementada

### Diagrama de Arquitectura
```
Internet ‚Üí NGINX (LoadBalancer:80) ‚Üí Frontend (React) ‚Üí Backend (API) ‚Üí MongoDB
```

### Componentes Desplegados

#### 1. MongoDB (StatefulSet)
- **Namespace**: `mongodb`
- **Tipo**: StatefulSet con volumen persistente
- **R√©plicas**: 1
- **Imagen**: `mongo:6.0`
- **Servicio**: Headless (`clusterIP: None`)
- **Almacenamiento**: 1Gi (ReadWriteOnce)
- **Seguridad**: Credenciales via Secret

#### 2. Backend API (Deployment + HPA)
- **Namespace**: `library-mern` 
- **Tipo**: Deployment con Horizontal Pod Autoscaler
- **R√©plicas**: 1-4 (autoescalado)
- **Imagen**: `ldavis007/chat-mern-backend:latest`
- **Servicio**: ClusterIP (interno)
- **Autoscaling**: 
  - CPU: 70%
  - Memoria: 60%
  - Policies: +2 pods/60s (up), -1 pod/90s (down)

#### 3. Frontend React (Deployment + HPA)
- **Namespace**: `library-mern`
- **Tipo**: Deployment con Horizontal Pod Autoscaler
- **R√©plicas**: 1-4 (autoescalado)
- **Imagen**: `ldavis007/chat-mern-frontend:latest`
- **Servicio**: ClusterIP (interno)
- **Autoscaling**:
  - CPU: 60%
  - Policies: +2 pods/60s (up), -1 pod/120s (down)

#### 4. NGINX Reverse Proxy (Deployment)
- **Namespace**: `library-mern`
- **Tipo**: Deployment
- **R√©plicas**: 1
- **Imagen**: `ldavis007/chat-mern-nginx:latest`
- **Servicio**: LoadBalancer (punto de entrada p√∫blico)
- **Funcionalidad**: Routing `/` ‚Üí Frontend, `/api/` ‚Üí Backend


## Especificaciones T√©cnicas Detalladas

### Recursos y Configuraciones

| Componente | Tipo | R√©plicas | CPU | Memory | Servicio | Autoescalado |
|-------------|------|-----------|----------------------|-------------------------|-----------|---------------|
| **MongoDB** | StatefulSet | 1 | 150m / 300m | 256Mi / 512Mi | Headless | ‚ùå |
| **Backend** | Deployment | 1‚Äì4 | 100m / 150m | 128Mi / 200Mi | ClusterIP | ‚úÖ (CPU 70%, Mem 60%) |
| **Frontend** | Deployment | 1‚Äì4 | 30m / 50m | 32Mi / 64Mi | ClusterIP | ‚úÖ (CPU 60%) |
| **NGINX** | Deployment | 1 | 30m / 50m | 32Mi / 64Mi | LoadBalancer | ‚ùå |


### Configuraci√≥n de Autoescalado

#### Backend HPA
```yaml
spec:
  minReplicas: 1
  maxReplicas: 4
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory  
      target:
        type: Utilization
        averageUtilization: 60
```

#### Frontend HPA
```yaml
spec:
  minReplicas: 1
  maxReplicas: 4  
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 60
```


## Comandos de Despliegue y Monitoreo

### Despliegue con Pulumi
```bash
# Desplegar infraestructura completa
pulumi up --yes

# Ver outputs (IPs, nombres)
pulumi stack output
```

### Monitoreo en Tiempo Real

```bash
# Ver estado del autoscaling
kubectl get hpa -n library-mern

# Monitorear recursos
kubectl top pods -n library-mern

# Ver logs de aplicaci√≥n
kubectl logs -n library-mern deployment/backend -f
```

## Caracter√≠sticas de la Implementaci√≥n

### Implementado con Pulumi (OPEN SOURCE)
- **Lenguaje**: TypeScript
- **Proveedor**: Google Cloud Platform (GKE)
- **Approach**: Infrastructure as Code declarativo

### Arquitectura de Microservicios
- **Segregaci√≥n**: Namespaces separados para app y base de datos
- **Comunicaci√≥n**: Servicios ClusterIP internos
- **Exposici√≥n**: √önico punto de entrada via LoadBalancer

### Estrategias de Autoescalado
- **Horizontal Pod Autoscaling** (HPA) para backend y frontend
- **M√©tricas basadas en CPU y memoria**
- **Pol√≠ticas de escalado configurables**
- **Anti-affinity** para distribuci√≥n √≥ptima de pods

## Pruebas de Autoscaling

### Metodolog√≠a de Pruebas

Se realizaron pruebas exhaustivas del sistema de autoescalado bajo diferentes escenarios de carga, desde estado de reposo hasta carga extrema, para validar el comportamiento del Horizontal Pod Autoscaler (HPA) configurado en el cl√∫ster.

### Estado Inicial del Cl√∫ster

![Despliegue del Cluster](docs/pulumi/deploy.png)  
*Cluster GKE `helloworld-4273d51` desplegado en us-central1-c con 3 nodos y 3 CPUs virtuales.*

### Pruebas de Carga y Autoescalado

#### 1. Estado de Reposo (Baseline)

- **Pods y HPA en Reposo**  
  ![Pods y HPA en Reposo](docs/pulumi/reposo-pods-hpa.png)  
  *Estado base: 1 r√©plica por deployment, CPU en 0%, HPA inactivo.*

- **Consumo de Recursos en Reposo**  
  ![Recursos en Reposo](docs/pulumi/reposo-recursos.png)  
  *Consumo m√≠nimo: todos los servicios en 1m CPU, MongoDB en 5m CPU.*

- **Nodos en Reposo**  
  ![Nodos en Reposo](docs/pulumi/reposo-nodos.png)  
  *Nodos operando al 6% de CPU cada uno, consumo eficiente.*

#### 2. Prueba de Carga Moderada (Frontend)

- **Comando de Prueba**
  ```bash
  ab -n 50000 -c 100 http://34.123.66.173/
  ```

* **Resultado - Autoescalado del Frontend**
  ![Autoescalado de Pods](docs/pulumi/carga-pods.png)
  **Comportamiento esperado:** el frontend escala autom√°ticamente a 2 r√©plicas cuando se somete a carga moderada, demostrando la efectividad del HPA.

* **Distribuci√≥n de Recursos**

  ![Recursos bajo Carga](docs/pulumi/carga-recursos.png)

  **An√°lisis:**

  * Backend: 26m y 25m CPU por r√©plica (distribuci√≥n balanceada)
  * Frontend: 16m CPU en cada r√©plica
  * MongoDB: 18m CPU
  * Demostrado: escalado horizontal efectivo con distribuci√≥n correcta de carga.

#### 3. Prueba de Carga Extrema (Backend)

* **Comando de Prueba**

  ```bash
  for i in {1..1000}; do
    curl -s -X POST http://34.123.66.173/api/auth/login \
      -H "Content-Type: application/json" \
      -d '{"username":"ldavis","password":"123456"}' &
  done
  wait
  ```

* **Resultado - L√≠mite del Backend**
  ![Carga Extrema en Pods](docs/pulumi/mucha-carga-pods.png)

  **Comportamiento observado:**

  * CPU alcanza 134% / 70% (sobre el umbral configurado)
  * Se crean las 4 r√©plicas m√°ximas de backend
  * A pesar de la carga extrema, todas las solicitudes se completaron exitosamente.

* **Resiliencia del Sistema**
  ![Recuperaci√≥n de Pods](docs/pulumi/caso-caida-pods.png)
  **Comportamiento de resiliencia:**

  * Los pods de backend caen temporalmente debido a la carga extrema
  * El sistema autom√°ticamente los reinicia y recupera
  * Demostrado: tolerancia a fallos y autorecuperaci√≥n del sistema.

* **Impacto en Nodos**
  ![Carga Extrema en Nodos](docs/pulumi/carga-nodos.png)

  **M√©tricas de Estr√©s:**

  * Nodos al 22‚Äì40% de CPU
  * Consumo de CPU entre 200m y 381m cores
  * Caso extremo: algunos pods fallan y requieren reinicio, demostrando los l√≠mites del sistema.


## An√°lisis de Resultados

### Comportamiento Validado del HPA

| Escenario | Comportamiento Esperado | Resultado Obtenido | Estado |
|------------|--------------------------|--------------------|--------|
| **Reposo** | 1 r√©plica, m√≠nimo consumo | Confirmado | ‚úîÔ∏è |
| **Carga Moderada** | Escalado a 2-3 r√©plicas | Frontend a 2 r√©plicas | ‚úîÔ∏è |
| **Carga Alta** | Escalado a r√©plicas m√°ximas | Backend a 4 r√©plicas | ‚úîÔ∏è |
| **Distribuci√≥n** | Balanceo de carga | Carga distribuida | ‚úîÔ∏è |
| **Resiliencia** | Recuperaci√≥n autom√°tica | Pods se reinician | ‚úîÔ∏è |


### M√©tricas de Rendimiento

1. **Umbral de Escalado**: 70% CPU (backend) - **Validado**
2. **L√≠mite de R√©plicas**: 4 m√°ximas - **Alcanzado y Validado**
3. **Tiempo de Respuesta**: Escalado en 2-3 minutos - **Observado**
4. **Distribuci√≥n**: Carga balanceada entre r√©plicas - **Confirmado**

### Comportamiento en L√≠mites

- **Carga Normal**: Sistema responde y escala adecuadamente
- **Carga Extrema**: Alcanza l√≠mites pero mantiene funcionalidad
- **Fallos**: Recuperaci√≥n autom√°tica sin intervenci√≥n manual
- **Recursos**: Uso eficiente de CPU y memoria seg√∫n configuraciones

## Conclusiones

1. **Autoescalado Funcional**: El HPA responde correctamente a los aumentos de carga
2. **Distribuci√≥n Efectiva**: La carga se distribuye entre las r√©plicas
3. **Resiliencia**: El sistema se recupera autom√°ticamente de fallos
4. **L√≠mites Definidos**: Comportamiento predecible en condiciones extremas

## üîó Recursos

- **Repositorio Pulumi para GKE**: [Documentaci√≥n Oficial](https://www.pulumi.com/registry/packages/kubernetes/how-to-guides/gke/)
- **Kubernetes HPA**: [Kubernetes Official Docs](https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/)